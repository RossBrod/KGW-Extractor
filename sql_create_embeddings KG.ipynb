{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install psycopg2-binary voyageai tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from voyageai import Client\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "client = Client(\n",
    "    api_key=\"pa-_7vCVNq7lM6mfe-E8cEyOkEyVB0soI3HwHwlO2BJwW0\"\n",
    ")\n",
    "# embeddings = client.embed(\"This is sample message\", model=\"voyage-law-2\")\n",
    "# print(embeddings)\n",
    "CONN_STRING = \"dbname=CaseGraph3 user=postgres1dev password=dev4023TcupSoda host=legawritesql.postgres.database.azure.com\"\n",
    "\n",
    "def GetEmbedding(text, model=\"voyage-law-2\"):\n",
    "    client = Client(\n",
    "        api_key=\"pa-_7vCVNq7lM6mfe-E8cEyOkEyVB0soI3HwHwlO2BJwW0\"\n",
    "    )\n",
    "    embedding = client.embed(text, model=model)\n",
    "    embedding = embedding.embeddings[0]\n",
    "    return embedding\n",
    "\n",
    "def GetEmbeddingsBatch(texts, model=\"voyage-law-2\"):\n",
    "    client = Client(\n",
    "        api_key=\"pa-_7vCVNq7lM6mfe-E8cEyOkEyVB0soI3HwHwlO2BJwW0\"\n",
    "    )\n",
    "    embeddings = client.embed(texts, model=model)\n",
    "    embeddings = embeddings.embeddings\n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateEmbeddings(name_of_target_table, name_of_target_column, name_of_embedding_column):\n",
    "    conn = psycopg2.connect(CONN_STRING)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    check_column_query = \"\"\"\n",
    "        SELECT column_name \n",
    "        FROM information_schema.columns \n",
    "        WHERE table_name=%s AND column_name=%s;\n",
    "    \"\"\"\n",
    "    cursor.execute(check_column_query, (name_of_target_table, name_of_embedding_column))\n",
    "    \n",
    "    if cursor.fetchone() is None:\n",
    "        alter_table_query = f'ALTER TABLE public.{name_of_target_table} ADD COLUMN {name_of_embedding_column} float[];'\n",
    "        cursor.execute(alter_table_query)\n",
    "        conn.commit()\n",
    "    else:\n",
    "        print(\"Err condition\")\n",
    "    \n",
    "    select_query = f\"SELECT principle_id, {name_of_target_column} FROM public.{name_of_target_table};\"\n",
    "    cursor.execute(select_query)\n",
    "    rows = cursor.fetchall()\n",
    "    for row in tqdm(rows, position=0, leave=True, total=len(rows), desc=f\"Creating embeddings for {name_of_target_table}, Items\"):\n",
    "        id, text = row\n",
    "        embedding = GetEmbedding(text)\n",
    "        update_query = f\"UPDATE public.{name_of_target_table} SET {name_of_embedding_column} = (%s) WHERE principle_id = {id};\"\n",
    "        cursor.execute(update_query, (embedding,))\n",
    "        conn.commit()\n",
    "\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    \n",
    "    print(\"Embeddings created and updated successfully.\")\n",
    "    \n",
    "def CreateEmbeddingsBatch(name_of_target_table, name_of_target_column, name_of_embedding_column, batch_size=100):\n",
    "    conn = psycopg2.connect(CONN_STRING)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    check_column_query = \"\"\"\n",
    "        SELECT column_name \n",
    "        FROM information_schema.columns \n",
    "        WHERE table_name=%s AND column_name=%s;\n",
    "    \"\"\"\n",
    "    cursor.execute(check_column_query, (name_of_target_table, name_of_embedding_column))\n",
    "    if cursor.fetchone() is None:\n",
    "        alter_table_query = f'ALTER TABLE public.{name_of_target_table} ADD COLUMN {name_of_embedding_column} float[];'\n",
    "        cursor.execute(alter_table_query)\n",
    "        conn.commit()\n",
    "\n",
    "    select_query = f\"SELECT domain_id, {name_of_target_column} FROM public.{name_of_target_table};\"\n",
    "    cursor.execute(select_query)\n",
    "    rows = cursor.fetchall()\n",
    "\n",
    "    total_rows = len(rows)\n",
    "    # print(f\"Processing {total_rows} rows in batches of {batch_size}...\")\n",
    "\n",
    "    for batch_start in tqdm(range(0, total_rows, batch_size), desc=f\"Creating embeddings for {name_of_target_table}, batches\", position=0, leave=True):\n",
    "        batch_rows = rows[batch_start:batch_start + batch_size]\n",
    "        ids = [row[0] for row in batch_rows]\n",
    "        texts = [row[1] for row in batch_rows]\n",
    "\n",
    "        embeddings = GetEmbeddingsBatch(texts)\n",
    "\n",
    "        update_data = list(zip(embeddings, ids))\n",
    "        #update_query = f\"UPDATE public.{name_of_target_table} SET {name_of_embedding_column} = %s WHERE domain_id = %s;\"\n",
    "        update_query = f\"\"\"UPDATE public.{name_of_target_table} SET {name_of_embedding_column} = %s::vector WHERE domain_id = %s;\"\"\"\n",
    "        \n",
    "\n",
    "        cursor.executemany(update_query, update_data)\n",
    "        conn.commit()\n",
    "\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "    print(\"Embeddings created and updated successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embeddings for a single column in a table item by item\n",
    "# table: defenses, column: name, embedding_column: name_embedding\n",
    "CreateEmbeddings(\n",
    "    name_of_target_table=\"legal_principles\",\n",
    "    name_of_target_column=\"type || ',' || context\",\n",
    "    name_of_embedding_column=\"name_embedding\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateEmbeddingsBatch_LP(name_of_target_table, name_of_target_column, name_of_embedding_column, batch_size=100):\n",
    "    conn = psycopg2.connect(CONN_STRING)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    check_column_query = \"\"\"\n",
    "        SELECT column_name \n",
    "        FROM information_schema.columns \n",
    "        WHERE table_name=%s AND column_name=%s;\n",
    "    \"\"\"\n",
    "    cursor.execute(check_column_query, (name_of_target_table, name_of_embedding_column))\n",
    "    if cursor.fetchone() is None:\n",
    "        alter_table_query = f'ALTER TABLE public.{name_of_target_table} ADD COLUMN {name_of_embedding_column} vector;'\n",
    "        cursor.execute(alter_table_query)\n",
    "        conn.commit()\n",
    "\n",
    "    select_query = f\"SELECT principle_id, {name_of_target_column} FROM public.{name_of_target_table};\"\n",
    "    cursor.execute(select_query)\n",
    "    rows = cursor.fetchall()\n",
    "\n",
    "    total_rows = len(rows)\n",
    "    # print(f\"Processing {total_rows} rows in batches of {batch_size}...\")\n",
    "\n",
    "    for batch_start in tqdm(range(0, total_rows, batch_size), desc=f\"Creating embeddings for {name_of_target_table}, batches\", position=0, leave=True):\n",
    "        batch_rows = rows[batch_start:batch_start + batch_size]\n",
    "        ids = [row[0] for row in batch_rows]\n",
    "        texts = [row[1] for row in batch_rows]\n",
    "\n",
    "        embeddings = GetEmbeddingsBatch(texts)\n",
    "\n",
    "        update_data = list(zip(embeddings, ids))\n",
    "        #update_query = f\"UPDATE public.{name_of_target_table} SET {name_of_embedding_column} = %s WHERE domain_id = %s;\"\n",
    "        update_query = f\"\"\"UPDATE public.{name_of_target_table} SET {name_of_embedding_column} = %s::vector WHERE principle_id = %s;\"\"\"\n",
    "        \n",
    "\n",
    "        cursor.executemany(update_query, update_data)\n",
    "        conn.commit()\n",
    "\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "    print(\"Embeddings created and updated successfully.\")\n",
    "    \n",
    "def CreateEmbeddingsBatch_issue(name_of_target_table, name_of_target_column, name_of_embedding_column, batch_size=100):\n",
    "    conn = psycopg2.connect(CONN_STRING)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    check_column_query = \"\"\"\n",
    "        SELECT column_name \n",
    "        FROM information_schema.columns \n",
    "        WHERE table_name=%s AND column_name=%s;\n",
    "    \"\"\"\n",
    "    cursor.execute(check_column_query, (name_of_target_table, name_of_embedding_column))\n",
    "    if cursor.fetchone() is None:\n",
    "        alter_table_query = f'ALTER TABLE public.{name_of_target_table} ADD COLUMN {name_of_embedding_column} vector;'\n",
    "        cursor.execute(alter_table_query)\n",
    "        conn.commit()\n",
    "\n",
    "    select_query = f\"SELECT issue_id, {name_of_target_column} FROM public.{name_of_target_table};\"\n",
    "    cursor.execute(select_query)\n",
    "    rows = cursor.fetchall()\n",
    "\n",
    "    total_rows = len(rows)\n",
    "    # print(f\"Processing {total_rows} rows in batches of {batch_size}...\")\n",
    "\n",
    "    for batch_start in tqdm(range(0, total_rows, batch_size), desc=f\"Creating embeddings for {name_of_target_table}, batches\", position=0, leave=True):\n",
    "        batch_rows = rows[batch_start:batch_start + batch_size]\n",
    "        ids = [row[0] for row in batch_rows]\n",
    "        texts = [row[1] for row in batch_rows]\n",
    "\n",
    "        embeddings = GetEmbeddingsBatch(texts)\n",
    "\n",
    "        update_data = list(zip(embeddings, ids))\n",
    "        #update_query = f\"UPDATE public.{name_of_target_table} SET {name_of_embedding_column} = %s WHERE domain_id = %s;\"\n",
    "        update_query = f\"\"\"UPDATE public.{name_of_target_table} SET {name_of_embedding_column} = %s::vector WHERE issue_id = %s;\"\"\"\n",
    "        \n",
    "\n",
    "        cursor.executemany(update_query, update_data)\n",
    "        conn.commit()\n",
    "\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "    print(\"Embeddings created and updated successfully.\")\n",
    "\n",
    "def CreateEmbeddingsBatch_COA(name_of_target_table, name_of_target_column, name_of_embedding_column, batch_size=100):\n",
    "    conn = psycopg2.connect(CONN_STRING)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    check_column_query = \"\"\"\n",
    "        SELECT column_name \n",
    "        FROM information_schema.columns \n",
    "        WHERE table_name=%s AND column_name=%s;\n",
    "    \"\"\"\n",
    "    cursor.execute(check_column_query, (name_of_target_table, name_of_embedding_column))\n",
    "    if cursor.fetchone() is None:\n",
    "        alter_table_query = f'ALTER TABLE public.{name_of_target_table} ADD COLUMN {name_of_embedding_column} vector;'\n",
    "        cursor.execute(alter_table_query)\n",
    "        conn.commit()\n",
    "\n",
    "    select_query = f\"SELECT cause_id, {name_of_target_column} FROM public.{name_of_target_table};\"\n",
    "    cursor.execute(select_query)\n",
    "    rows = cursor.fetchall()\n",
    "\n",
    "    total_rows = len(rows)\n",
    "    # print(f\"Processing {total_rows} rows in batches of {batch_size}...\")\n",
    "\n",
    "    for batch_start in tqdm(range(0, total_rows, batch_size), desc=f\"Creating embeddings for {name_of_target_table}, batches\", position=0, leave=True):\n",
    "        batch_rows = rows[batch_start:batch_start + batch_size]\n",
    "        ids = [row[0] for row in batch_rows]\n",
    "        texts = [row[1] for row in batch_rows]\n",
    "\n",
    "        embeddings = GetEmbeddingsBatch(texts)\n",
    "\n",
    "        update_data = list(zip(embeddings, ids))\n",
    "        #update_query = f\"UPDATE public.{name_of_target_table} SET {name_of_embedding_column} = %s WHERE domain_id = %s;\"\n",
    "        update_query = f\"\"\"UPDATE public.{name_of_target_table} SET {name_of_embedding_column} = %s::vector WHERE cause_id = %s;\"\"\"\n",
    "        \n",
    "\n",
    "        cursor.executemany(update_query, update_data)\n",
    "        conn.commit()\n",
    "\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "    print(\"Embeddings created and updated successfully.\")\n",
    "    \n",
    "def CreateEmbeddingsBatch_rule(name_of_target_table, name_of_target_column, name_of_embedding_column, batch_size=100):\n",
    "    conn = psycopg2.connect(CONN_STRING)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    check_column_query = \"\"\"\n",
    "        SELECT column_name \n",
    "        FROM information_schema.columns \n",
    "        WHERE table_name=%s AND column_name=%s;\n",
    "    \"\"\"\n",
    "    cursor.execute(check_column_query, (name_of_target_table, name_of_embedding_column))\n",
    "    if cursor.fetchone() is None:\n",
    "        alter_table_query = f'ALTER TABLE public.{name_of_target_table} ADD COLUMN {name_of_embedding_column} vector;'\n",
    "        cursor.execute(alter_table_query)\n",
    "        conn.commit()\n",
    "\n",
    "    select_query = f\"SELECT ruling_id, {name_of_target_column} FROM public.{name_of_target_table};\"\n",
    "    cursor.execute(select_query)\n",
    "    rows = cursor.fetchall()\n",
    "\n",
    "    total_rows = len(rows)\n",
    "    # print(f\"Processing {total_rows} rows in batches of {batch_size}...\")\n",
    "\n",
    "    for batch_start in tqdm(range(0, total_rows, batch_size), desc=f\"Creating embeddings for {name_of_target_table}, batches\", position=0, leave=True):\n",
    "        batch_rows = rows[batch_start:batch_start + batch_size]\n",
    "        ids = [row[0] for row in batch_rows]\n",
    "        texts = [row[1] for row in batch_rows]\n",
    "\n",
    "        embeddings = GetEmbeddingsBatch(texts)\n",
    "\n",
    "        update_data = list(zip(embeddings, ids))\n",
    "        #update_query = f\"UPDATE public.{name_of_target_table} SET {name_of_embedding_column} = %s WHERE domain_id = %s;\"\n",
    "        update_query = f\"\"\"UPDATE public.{name_of_target_table} SET {name_of_embedding_column} = %s::vector WHERE ruling_id = %s;\"\"\"\n",
    "        \n",
    "\n",
    "        cursor.executemany(update_query, update_data)\n",
    "        conn.commit()\n",
    "\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "    print(\"Embeddings created and updated successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating embeddings for legal_principles, batches: 100%|██████████| 110/110 [02:48<00:00,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings created and updated successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create embeddings (x18 faster with 100 batch size, 128 max)\n",
    "# table: defenses, column: name, embedding_column: name_embedding\n",
    "\n",
    "CreateEmbeddings(\n",
    "    name_of_target_table=\"legal_principles\",\n",
    "    name_of_target_column=\"type || ',' || context\",\n",
    "    name_of_embedding_column=\"name_embedding\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating embeddings for case_rulings, batches: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings created and updated successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# CreateEmbeddingsBatch_LP(\n",
    "#     name_of_target_table=\"legal_principles\",\n",
    "#     name_of_target_column=\"doctrine_principle\",\n",
    "#     name_of_embedding_column=\"name_embedding\",\n",
    "#     batch_size=128\n",
    "\n",
    "# )\n",
    "# CreateEmbeddingsBatch_LP(\n",
    "#     name_of_target_table=\"legal_principles\",\n",
    "#     name_of_target_column=\"doctrine_principle\",\n",
    "#     name_of_embedding_column=\"name_embedding\",\n",
    "#     batch_size=128\n",
    "\n",
    "# )\n",
    "CreateEmbeddingsBatch_rule(\n",
    "    name_of_target_table=\"case_rulings\",\n",
    "    name_of_target_column=\"legal_principle_text\",\n",
    "    name_of_embedding_column=\"ruling_embedding\",\n",
    "    batch_size=128\n",
    ")\n",
    "# CreateEmbeddingsBatch_issue(\n",
    "#     name_of_target_table=\"legal_principles\",\n",
    "#     name_of_target_column=\"issue_text\",\n",
    "#     name_of_embedding_column=\"issues_embedding\",\n",
    "#     batch_size=128\n",
    "# )\n",
    "# CreateEmbeddingsBatch_COA(\n",
    "#     name_of_target_table=\"causes_of_action\",\n",
    "#     name_of_target_column=\"name\",\n",
    "#     name_of_embedding_column=\"name_embedding\",\n",
    "#     batch_size=128\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating embeddings for law_domains, batches: 100%|██████████| 532/532 [12:25<00:00,  1.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings created and updated successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "CreateEmbeddingsBatch(\n",
    "    name_of_target_table=\"law_domains\",\n",
    "    name_of_target_column=(\n",
    "        \"coalesce(broad, '')\"\n",
    "        \" || '->' || coalesce(subdomain, '')\"\n",
    "        \" || '->' || coalesce(\\\"specific\\\", '')\"\n",
    "    ),\n",
    "    name_of_embedding_column=\"domain_embedding\",\n",
    "    batch_size=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CreateEmbeddingsBatch(\n",
    "    name_of_target_table=\"law_domains\",\n",
    "    name_of_target_column=(\n",
    "        \"coalesce(broad, '') || '->' || coalesce(subdomain, '')\"\n",
    "    ),\n",
    "    name_of_embedding_column=\"broad_subdomain_embedding\",\n",
    "    batch_size=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_LD = GetEmbedding(\"Employment Law -> Discrimination -> Retaliation Protection\")\n",
    "emb_LP = GetEmbedding(\"Witness Protection Principle. FEHA protects employees who participate in workplace discrimination investigations.\")\n",
    "\n",
    "\n",
    "conn = psycopg2.connect(CONN_STRING)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT DISTINCT \n",
    "    c.case_id,\n",
    "    c.\"name\",\n",
    "    d.domain_id,\n",
    "    d.broad,\n",
    "    d.subdomain,\n",
    "    d.specific,\n",
    "    lp.name AS principle_name,\n",
    "    d.domain_embedding <=> %s::vector AS distanceLD,\n",
    "    lp.name_embedding <=> %s::vector AS distanceLP,\n",
    "    (\n",
    "      0.4 * (d.domain_embedding <=> %s::vector) +\n",
    "      0.6 * (lp.name_embedding <=> %s::vector)\n",
    "    ) AS combined_distance\n",
    "FROM law_domains d\n",
    "INNER JOIN case_law_domains cld ON cld.domain_id = d.domain_id\n",
    "INNER JOIN cases c ON c.case_id::text = cld.case_id::text\n",
    "INNER JOIN legal_principles lp ON lp.case_id = c.case_id\n",
    "WHERE \n",
    "    d.domain_embedding IS NOT NULL\n",
    "    AND lp.name_embedding IS NOT NULL\n",
    "ORDER BY combined_distance ASC\n",
    "LIMIT 200;\n",
    "\"\"\"\n",
    "\n",
    "cursor.execute(query, (emb_LD, emb_LP, emb_LD, emb_LP))\n",
    "results = cursor.fetchall()\n",
    "\n",
    "for row in results:\n",
    "    print(row)\n",
    "\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_LP = GetEmbedding(\"Witness Protection Principle. FEHA protects employees who participate in workplace discrimination investigations.\")\n",
    "\n",
    "\n",
    "\n",
    "conn = psycopg2.connect(CONN_STRING)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT DISTINCT \n",
    "    c.case_id,\n",
    "    c.\"name\",\n",
    "    lp.name AS principle_name,\n",
    "    lp.name_embedding <=> %s::vector AS distanceLP\n",
    "FROM legal_principles lp\n",
    "INNER JOIN cases c \n",
    "    ON lp.case_id = c.case_id\n",
    "INNER JOIN case_law_domains cld \n",
    "    ON cld.case_id=c.case_id\n",
    "INNER JOIN law_domains d    \n",
    "    on cld.domain_id = d.domain_id    \n",
    "WHERE lp.name_embedding IS NOT NULL and d.domain_embedding IS NOT NULL\n",
    "and d.\n",
    "ORDER BY distanceLP ASC\n",
    "LIMIT 200;\n",
    "\"\"\"\n",
    "cursor.execute(query, (emb_LP,))\n",
    "results = cursor.fetchall()\n",
    "\n",
    "for row in results:\n",
    "    print(row)\n",
    "\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_domain = GetEmbedding(\"Employment Law -> Discrimination\")\n",
    "emb_principle = GetEmbedding(\"Witness Protection Principle. FEHA protects employees who participate in workplace discrimination investigations.\")\n",
    "\n",
    "\n",
    "conn = psycopg2.connect(CONN_STRING)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT DISTINCT \n",
    "    c.case_id,\n",
    "    c.\"name\",\n",
    "    d.broad,\n",
    "    d.subdomain,\n",
    "    d.specific,\n",
    "    lp.name AS principle_name,\n",
    "    d.broad_subdomain_embedding <=> %s::vector AS distance_domain,\n",
    "    lp.name_embedding <=> %s::vector AS distance_principle,\n",
    "    (\n",
    "      0.7 * (d.broad_subdomain_embedding <=> %s::vector) +\n",
    "      0.3 * (lp.name_embedding <=> %s::vector)\n",
    "    ) AS combined_distance\n",
    "FROM law_domains d\n",
    "INNER JOIN case_law_domains cld ON cld.domain_id = d.domain_id\n",
    "INNER JOIN cases c ON c.case_id::text = cld.case_id::text\n",
    "INNER JOIN legal_principles lp ON lp.case_id = c.case_id\n",
    "WHERE \n",
    "    d.broad_subdomain_embedding IS NOT NULL\n",
    "    AND lp.name_embedding IS NOT NULL\n",
    "ORDER BY combined_distance ASC\n",
    "LIMIT 200;\n",
    "\n",
    "\"\"\"\n",
    "cursor.execute(query, (emb_domain, emb_principle, emb_domain, emb_principle))\n",
    "results = cursor.fetchall()\n",
    "\n",
    "for row in results:\n",
    "    print(row)\n",
    "\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update successful.\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "CONN_STRING = \"dbname=KG-Extractor user=postgres1dev password=dev4023TcupSoda host=legawritesql.postgres.database.azure.com\"\n",
    "\n",
    "conn = psycopg2.connect(CONN_STRING)\n",
    "case_id = 'steele-v-youthful-offender-parole-bd'\n",
    "\n",
    "query = \"\"\"\n",
    "    UPDATE cases\n",
    "    SET text = %s\n",
    "    WHERE case_id = %s\n",
    "\"\"\"\n",
    "\n",
    "with open(\"steele-v-youthful-offender-parole-bd.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    large_text = file.read()\n",
    "\n",
    "try:\n",
    "    with conn:\n",
    "        with conn.cursor() as cursor:\n",
    "            cursor.execute(query, (large_text, case_id))  \n",
    "            print(\"Update successful.\")\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)\n",
    "finally:\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\\n  <NameSelectedCOA>Unpaid Missed Meal Breaks</NameSelectedCOA>\\n  <ProceduralDefenses>\\n    <ProceduralDefense1>\\n      <ProceduralDefense_name>Failure to State Essential Elements</ProceduralDefense_name>\\n      <LegalPrinciple>Complaint must specify timing and nature of meal violations</LegalPrinciple>\\n      <LegalPrinciple_type>Pleading Requirement</LegalPrinciple_type>\\n      <applicability>Complaint lacks specific meal period violation details</applicability>\\n      <LawDomain>\\n        Labor Law -> Wage and Hour -> Meal Break Requirements\\n      </LawDomain>\\n      <casesCited>\\n        <caseCited_1>\\n          <caseCited_1_name>Brinker Restaurant Corp. v. Superior Court (2012)</caseCited_1_name>\\n          <caseCited_1_applicability>Establishes specific pleading requirements for meal break claims</caseCited_1_applicability>\\n          <WhyCaseIsThisRelevant>Defines elements required in meal break violation complaints</WhyCaseIsThisRelevant>\\n          <CaseEstablishesRule>Complaint must allege specific instances of meal violations</CaseEstablishesRule>\\n        </caseCited_1>\\n        <caseCited_2>\\n          <caseCited_2_name>Lamps Plus Overtime Cases (2015)</caseCited_2_name>\\n          <caseCited_2_applicability>Requires specific factual allegations for each violation</caseCited_2_applicability>\\n          <WhyCaseIsThisRelevant>Sets pleading standard for meal break claims</WhyCaseIsThisRelevant>\\n          <CaseEstablishesRule>General allegations insufficient without specific violation details</CaseEstablishesRule>\\n        </caseCited_2>\\n      </casesCited>\\n      <AppliedArgument>Complaint only states general allegations without specific instances</AppliedArgument>\\n      <AppliedArgument_type>Insufficient Pleading Detail</AppliedArgument_type>\\n    </ProceduralDefense1>\\n  </ProceduralDefenses>\\n  <SubstantiveDefenses>\\n    <SubstantiveDefense1>\\n      <SubstantiveDefense_name>Exempt Employee Classification Defense</SubstantiveDefense_name>\\n      <LegalPrinciple>Exempt employees not entitled to meal break requirements</LegalPrinciple>\\n      <LegalPrinciple_type>Employment Classification Law</LegalPrinciple_type>\\n      <applicability>Initial exempt classification bars meal break claims</applicability>\\n      <LawDomain>\\n        Employment Law -> Employee Classification -> Exempt Status\\n      </LawDomain>\\n      <casesCited>\\n        <caseCited_1>\\n          <caseCited_1_name>Sav-On Drug Stores v. Superior Court (2004)</caseCited_1_name>\\n          <caseCited_1_applicability>Exempt status determined at time of classification</caseCited_1_applicability>\\n          <WhyCaseIsThisRelevant>Addresses classification impact on meal break rights</WhyCaseIsThisRelevant>\\n          <CaseEstablishesRule>Initial exempt classification controls unless formally changed</CaseEstablishesRule>\\n        </caseCited_1>\\n      </casesCited>\\n      <AppliedArgument>Initial exempt classification precludes meal break claims</AppliedArgument>\\n      <AppliedArgument_type>Classification Based Defense</AppliedArgument_type>\\n    </SubstantiveDefense1>\\n  </SubstantiveDefenses>\\n\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_xml = \"\"\"\n",
    "    <NameSelectedCOA>Wrongful Termination in Violation of Public Policy</NameSelectedCOA>\n",
    "  \n",
    "    <ProceduralDefenses>\n",
    "        <ProceduralDefense1>\n",
    "            <ProceduralDefense_name>Failure to Exhaust Administrative Remedies</ProceduralDefense_name>\n",
    "            <LegalPrinciple>Administrative procedures must be completed before court action</LegalPrinciple>\n",
    "            <LegalPrinciple_type>Administrative Law Requirement</LegalPrinciple_type>\n",
    "            <applicability>Labor violations require prior agency review</applicability>\n",
    "            <LawDomain>Employment Law -> Administrative Procedures -> Exhaustion Doctrine</LawDomain>\n",
    "            <casesCited>\n",
    "                <caseCited_1>\n",
    "                    <caseCited_1_name>Campbell v. Regents of University of California (2005)</caseCited_1_name>\n",
    "                    <caseCited_1_applicability>Establishes mandatory exhaustion requirement for employment claims</caseCited_1_applicability>\n",
    "                    <WhyCaseIsThisRelevant>Requires administrative process before judicial review</WhyCaseIsThisRelevant>\n",
    "                    <CaseEstablishesRule>Administrative remedies must be exhausted before court action</CaseEstablishesRule>\n",
    "                </caseCited_1>\n",
    "            </casesCited>\n",
    "            <AppliedArgument>Complaint lacks allegations of administrative procedure completion</AppliedArgument>\n",
    "            <AppliedArgument_type>Procedural Prerequisites Not Met</AppliedArgument_type>\n",
    "        </ProceduralDefense1>\n",
    "    </ProceduralDefenses>\n",
    "\n",
    "    <SubstantiveDefenses>\n",
    "        <SubstantiveDefense1>\n",
    "            <ProceduralDefense_name>Insufficient Public Policy Nexus</ProceduralDefense_name>\n",
    "            <LegalPrinciple>Public policy must be fundamental and substantial</LegalPrinciple>\n",
    "            <LegalPrinciple_type>Public Policy Requirements</LegalPrinciple_type>\n",
    "            <applicability>Policy violation must be clearly established</applicability>\n",
    "            <LawDomain>Employment Law -> Public Policy -> Wrongful Termination</LawDomain>\n",
    "            <casesCited>\n",
    "                <caseCited_1>\n",
    "                    <caseCited_1_name>Gantt v. Sentry Insurance (1992)</caseCited_1_name>\n",
    "                    <caseCited_1_applicability>Defines requirements for public policy claims</caseCited_1_applicability>\n",
    "                    <WhyCaseIsThisRelevant>Sets standards for public policy wrongful termination</WhyCaseIsThisRelevant>\n",
    "                    <CaseEstablishesRule>Policy must be fundamental, substantial, well-established</CaseEstablishesRule>\n",
    "                </caseCited_1>\n",
    "            </casesCited>\n",
    "            <AppliedArgument>Complaint fails to specify clear public policy source</AppliedArgument>\n",
    "            <AppliedArgument_type>Policy Source Not Identified</AppliedArgument_type>\n",
    "        </SubstantiveDefense1>\n",
    "\n",
    "        <SubstantiveDefense2>\n",
    "            <ProceduralDefense_name>Legitimate Business Reason Defense</ProceduralDefense_name>\n",
    "            <LegalPrinciple>Employment changes permitted for business operations</LegalPrinciple>\n",
    "            <LegalPrinciple_type>Business Judgment Rule</LegalPrinciple_type>\n",
    "            <applicability>Role changes within employer discretion</applicability>\n",
    "            <LawDomain>Employment Law -> At-Will Employment -> Business Necessity</LawDomain>\n",
    "            <casesCited>\n",
    "                <caseCited_1>\n",
    "                    <caseCited_1_name>Guz v. Bechtel National Inc. (2000)</caseCited_1_name>\n",
    "                    <caseCited_1_applicability>Supports employer discretion in business decisions</caseCited_1_applicability>\n",
    "                    <WhyCaseIsThisRelevant>Establishes business judgment protection</WhyCaseIsThisRelevant>\n",
    "                    <CaseEstablishesRule>Employers have discretion in operational decisions</CaseEstablishesRule>\n",
    "                </caseCited_1>\n",
    "            </casesCited>\n",
    "            <AppliedArgument>Role changes reflect legitimate business reorganization</AppliedArgument>\n",
    "            <AppliedArgument_type>Business Decision Protection</AppliedArgument_type>\n",
    "        </SubstantiveDefense2>\n",
    "    </SubstantiveDefenses>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def xml_to_dict(xml_string):\n",
    "    xml_string = xml_string.strip()\n",
    "    tag_pattern = re.compile(r'<(\\w+)>(.*?)</\\1>', re.DOTALL)\n",
    "    \n",
    "    def parse(fragment):\n",
    "        fragment = fragment.strip()\n",
    "        if not tag_pattern.search(fragment):\n",
    "            return fragment\n",
    "        \n",
    "        result = {}\n",
    "        for match in tag_pattern.finditer(fragment):\n",
    "            tag = match.group(1)\n",
    "            content = match.group(2).strip()\n",
    "            parsed_content = parse(content)\n",
    "            \n",
    "            if tag in result:\n",
    "                if isinstance(result[tag], list):\n",
    "                    result[tag].append(parsed_content)\n",
    "                else:\n",
    "                    result[tag] = [result[tag], parsed_content]\n",
    "            else:\n",
    "                result[tag] = parsed_content\n",
    "        return result\n",
    "    \n",
    "    return parse(xml_string)\n",
    "\n",
    "parsed_xml = xml_to_dict(test_xml)\n",
    "parsed_xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetCase(input_embedding_coa_name_string, input_embedding_procedural_defense_name_string, input_legal_principal_string):\n",
    "    input_embedding_coa_name = GetEmbedding(input_embedding_coa_name_string)\n",
    "    input_embedding_procedural_defense_name = GetEmbedding(input_embedding_procedural_defense_name_string)\n",
    "    input_legal_principal = GetEmbedding(input_legal_principal_string)\n",
    "\n",
    "    query = f\"\"\"\n",
    "        SELECT f.name, f.case_law, f.defence_name, f.Distance1, f.Distance2, f.Distance3\n",
    "            FROM (\n",
    "                SELECT c.name, d.case_law, d.name as defence_name, d.legal_principle_embedding,\n",
    "                    cosine_similarity(%s::double precision[], c.name_embedding) as Distance1,\n",
    "                    cosine_similarity(%s::double precision[], d.name_embedding) as Distance2,\n",
    "                    cosine_similarity(%s::double precision[], d.legal_principle_embedding) as Distance3\n",
    "                FROM public.causes_of_action AS c\n",
    "                INNER JOIN defenses d\n",
    "                    on c.id=d.cause_of_action_id\n",
    "            ) AS f\n",
    "        WHERE f.Distance1 >= 0.4 and f.Distance2 >= 0.4\n",
    "        ORDER BY f.Distance1 DESC, f.Distance2 DESC, f.Distance3 DESC\n",
    "    \"\"\"\n",
    "\n",
    "    conn = psycopg2.connect(CONN_STRING)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    cursor.execute(query, (input_embedding_coa_name, input_embedding_procedural_defense_name, input_legal_principal))\n",
    "    cosine_similarity = cursor.fetchall()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    return cosine_similarity[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_of_selected_coa = parsed_xml[\"NameSelectedCOA\"]\n",
    "# for procedural_defense in parsed_xml[\"ProceduralDefenses\"].values():\n",
    "#     name_of_procedural_defense = procedural_defense[\"ProceduralDefense_name\"]\n",
    "#     # legal_principle = procedural_defense[\"LegalPrinciple\"]\n",
    "#     # print(name_of_procedural_defense)\n",
    "#     print(name_of_selected_coa)\n",
    "#     print(name_of_procedural_defense)\n",
    "#     top_case = GetCase(name_of_selected_coa, name_of_procedural_defense)\n",
    "#     print(top_case)\n",
    "#     procedural_defense[\"casesFound\"] = top_case\n",
    "\n",
    "for substantive_defense in parsed_xml[\"SubstantiveDefenses\"].values():\n",
    "    name_of_substantive_defense = substantive_defense[\"ProceduralDefense_name\"]\n",
    "    legal_principle = substantive_defense[\"LegalPrinciple\"]\n",
    "    # print(name_of_substantive_defense)\n",
    "    print(name_of_selected_coa)\n",
    "    print(name_of_substantive_defense)\n",
    "    top_case = GetCase(name_of_selected_coa, name_of_substantive_defense, legal_principle)\n",
    "    case_name = top_case[1]\n",
    "    print()\n",
    "    print(case_name)\n",
    "    print(top_case)\n",
    "    substantive_defense[\"casesFound\"] = top_case[1]\n",
    "    \n",
    "\n",
    "parsed_xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_embedding_coa_name = client.embed(\"Wrongful Termination in Violation of Public Policy\", model=\"voyage-law-2\")\n",
    "input_embedding_coa_name = input_embedding_coa_name.embeddings[0]\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT DISTINCT f1.defence_name\n",
    "    FROM (\n",
    "        SELECT f.defence_name\n",
    "        FROM (\n",
    "            SELECT c.name_embedding, d.name AS defence_name, d.appropriateatdemurerstage, \n",
    "                cosine_similarity(%s::double precision[], c.name_embedding) as Distance1\n",
    "            FROM public.causes_of_action AS c\n",
    "            INNER JOIN defenses d\n",
    "                ON c.id=d.cause_of_action_id\n",
    "        ) AS f\n",
    "        WHERE f.appropriateatdemurerstage > '7' AND f.Distance1 > 0.7\n",
    "        ORDER BY f.Distance1 DESC\n",
    "    ) as F1\n",
    "\"\"\"\n",
    "\n",
    "conn = psycopg2.connect(CONN_STRING)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(query, (input_embedding_coa_name,))\n",
    "cosine_similarity = cursor.fetchall()\n",
    "cursor.close()\n",
    "conn.close()\n",
    "cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
